{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy.contrib.spiders import CrawlSpider, Rule\n",
    "from scrapy.contrib.linkextractors import LinkExtractor\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "import scrapy\n",
    "class GplaycrawlerItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = Field()\n",
    "    Link = scrapy.Field()\n",
    "    Item_name = scrapy.Field()\n",
    "    Updated = scrapy.Field()\n",
    "    Author = scrapy.Field()\n",
    "    Filesize = scrapy.Field()\n",
    "    Downloads = scrapy.Field()\n",
    "    Version = scrapy.Field()\n",
    "    Compatibility = scrapy.Field()\n",
    "    Content_rating = scrapy.Field()\n",
    "    Author_link = scrapy.Field()\n",
    "##    Author_link_test = scrapy.Field()\n",
    "    Genre = scrapy.Field()\n",
    "    Price = scrapy.Field()\n",
    "    Rating_value = scrapy.Field()\n",
    "    Review_number = scrapy.Field()\n",
    "    Description = scrapy.Field()\n",
    "    IAP = scrapy.Field()\n",
    "    Developer_badge = scrapy.Field()\n",
    "    Physical_address = scrapy.Field()\n",
    "    Video_URL = scrapy.Field()\n",
    "    Developer_ID = scrapy.Field()\n",
    "\n",
    "import urlparse\n",
    "\n",
    "class MySpider(CrawlSpider):\n",
    "    name = \"playcrawler\"\n",
    "    allowed_domains = [\"play.google.com\"]\n",
    "    start_urls = [\"https://play.google.com/store/apps/\"]\n",
    "    rules = [Rule(LinkExtractor(allow=(r'apps',),deny=(r'reviewId')),follow=True,callback='parse_link')]\n",
    "   \n",
    "    def abs_url(url, response):\n",
    "        \"\"\"Return absolute link\"\"\"\n",
    "        base = response.xpath('//head/base/@href').extract()\n",
    "        if base:\n",
    "            base = base[0]\n",
    "        else:\n",
    "            base = response.url\n",
    "        return urlparse.urljoin(base, url)\n",
    "    \n",
    "    def parse_link(self,response):\n",
    "        hxs = HtmlXPathSelector(response)\n",
    "        titles = hxs.select('/html')\n",
    "        items = []\n",
    "        for titles in titles :\n",
    "            item = GplaycrawlerItem()\n",
    "            item[\"Link\"] = ''.join(titles.select('head/link[5]/@href').extract())\n",
    "            item[\"Item_name\"] = ''.join(titles.select('//*[@class=\"document-title\"]/div/text()').extract())\n",
    "            item[\"Updated\"] = ''.join(titles.select('//*[@itemprop=\"datePublished\"]/text()').extract())\n",
    "            item[\"Author\"] = ''.join(titles.select('//*[@itemprop=\"author\"]/a/span/text()').extract())\n",
    "            item[\"Filesize\"] = ''.join(titles.select('//*[@itemprop=\"fileSize\"]/text()').extract())\n",
    "            item[\"Downloads\"] = ''.join(titles.select('//*[@itemprop=\"numDownloads\"]/text()').extract())\n",
    "            item[\"Version\"] = ''.join(titles.select('//*[@itemprop=\"softwareVersion\"]/text()').extract())\n",
    "            item[\"Compatibility\"] = ''.join(titles.select('//*[@itemprop=\"softwareVersion\"]/text()').extract())\n",
    "            item[\"Content_rating\"] = ''.join(titles.select('//*[@itemprop=\"contentRating\"]/text()').extract())\n",
    "            item[\"Author_link\"] = ''.join(titles.select('//*[@class=\"dev-link\"]/@href').extract())\n",
    "            item[\"Genre\"] = ''.join(titles.select('//*[@itemprop=\"genre\"]/text()').extract())\n",
    "            item[\"Price\"] = ''.join(titles.select('//*[@class=\"price buy id-track-click\"]/span[2]/text()').extract())\n",
    "            item[\"Rating_value\"] = ''.join(titles.select('//*[@class=\"score\"]/text()').extract())\n",
    "            item[\"Review_number\"] = ''.join(titles.select('//*[@class=\"reviews-num\"]/text()').extract())\n",
    "            item[\"Description\"] = ''.join(titles.select('//*[@class=\"id-app-orig-desc\"]//text()').extract())\n",
    "            item[\"IAP\"] = ''.join(titles.select('//*[@class=\"inapp-msg\"]/text()').extract())\n",
    "            item[\"Developer_badge\"] = ''.join(titles.select('//*[@class=\"badge-title\"]//text()').extract())\n",
    "            item[\"Physical_address\"] = ''.join(titles.select('//*[@class=\"content physical-address\"]/text()').extract())\n",
    "            item[\"Video_URL\"] = ''.join(titles.select('//*[@class=\"play-action-container\"]/@data-video-url').extract())\n",
    "            item[\"Developer_ID\"] = ''.join(titles.select('//*[@itemprop=\"author\"]/a/@href').extract())\n",
    "            items.append(item)\n",
    "        return items\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = MySpider(CrawlSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MySpider <class 'scrapy.spiders.crawl.CrawlSpider'> at 0x472c9b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
